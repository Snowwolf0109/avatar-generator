{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c25d1abb-1e57-4290-8a6e-43aa20ceca17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\imagi\\fastRAG\\ragvenv\\lib\\site-packages\\tqdm-4.67.0-py3.9.egg\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from haystack import Pipeline, Document\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.rankers import TransformersSimilarityRanker\n",
    "from gtts import gTTS\n",
    "from fastrag.generators.openvino import OpenVINOGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c160b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 'anti-bribery_anti-corruption_policy_feb_2022_finalwebsite.pdf' has been successfully processed and added to the document store.\n"
     ]
    }
   ],
   "source": [
    "# Initialize InMemoryDocumentStore\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "#future thought: create a folder that accepts amd store one or more pdf,\n",
    "#so the link doesnt have to be different all the time\n",
    "# Path to your single PDF document \n",
    "pdf_path = r\"C:\\Users\\imagi\\fastRAG\\data\\anti-bribery_anti-corruption_policy_feb_2022_finalwebsite.pdf\"\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_pdf_text(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Extract text from the PDF\n",
    "text = extract_pdf_text(pdf_path)\n",
    "\n",
    "# Create a document object\n",
    "document = {\n",
    "    'id': os.path.basename(pdf_path),  # Use the filename as document id\n",
    "    'text': text,\n",
    "    'title': os.path.basename(pdf_path)\n",
    "}\n",
    "\n",
    "# Add the document to the InMemoryDocumentStore\n",
    "doc = Document(id=document['id'], content=document['text'], meta={\"title\": document['title']})\n",
    "document_store.write_documents([doc])\n",
    "\n",
    "print(f\"Document '{document['title']}' has been successfully processed and added to the document store.\")\n",
    "\n",
    "retriever = InMemoryBM25Retriever(document_store=document_store)\n",
    "ranker = TransformersSimilarityRanker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "007a35c9-c876-4616-9b1a-455a321195d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a RAG pipeline\n",
    "prompt_template = \"\"\"\n",
    "Given these documents, answer the question.\n",
    "Documents:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.text }}\n",
    "{% endfor %}\n",
    "Question: {{query}}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8bf25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openvino_compressed_model_path = r\"C:\\Users\\imagi\\fastRAG\\ov_model\"\n",
    "generator = OpenVINOGenerator(\n",
    "    model=\"meta-llama/Llama-3.2-3B\",\n",
    "    compressed_model_dir=openvino_compressed_model_path,\n",
    "    device_openvino=\"CPU\",\n",
    "    task=\"text-generation\",\n",
    "    generation_kwargs={\n",
    "        \"max_new_tokens\": 200,\n",
    "        \"temperature\": 0.3,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9d9631-1ce8-4019-9d30-31dacf5f8950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline created\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline()\n",
    "\n",
    "pipe.add_component(\"retriever\", retriever)\n",
    "pipe.add_component(\"ranker\", ranker)\n",
    "pipe.add_component(\"prompt_builder\", PromptBuilder(template=prompt_template))\n",
    "pipe.add_component(\"llm\", generator)\n",
    "\n",
    "pipe.connect(\"retriever.documents\", \"ranker.documents\")\n",
    "pipe.connect(\"ranker\", \"prompt_builder.documents\")\n",
    "pipe.connect(\"prompt_builder\", \"llm\")\n",
    "print(\"Pipeline created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db7d8ac-9ab3-46a2-b1a0-e4d772159c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ranking by BM25...: 100%|██████████| 1/1 [00:00<00:00, 999.36 docs/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The employees should not take bribes from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should not accept any bribe from the clients. They should\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the responsibilities of the employees against bribery?\"\n",
    "answer_result = pipe.run({\n",
    "    \"prompt_builder\": {\n",
    "        \"query\": query\n",
    "    },\n",
    "    \"retriever\": {\n",
    "        \"query\": query\n",
    "    },\n",
    "    \"ranker\": {\n",
    "        \"query\": query,\n",
    "        \"top_k\": 1#to ensure relevance to the og doc\n",
    "    }\n",
    "})\n",
    "\n",
    "answer= answer_result[\"llm\"][\"replies\"][0].split('Question:')[0].strip()\n",
    "print(answer)\n",
    "#improve prompt, and add in some parameters to adjust the query and response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f348c5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.21813122928142548\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Sample generated and retrieved text\n",
    "generated_answer = answer\n",
    "retrieved_text = \"Employees are responsible for understanding and complying with this Policy. Be familiar with applicable requirements and directives of the policy and communicate them to subordinates. Promptly record all transactions and payments accurately and in reasonable detail. Always raise suspicious transactions to immediate superiors for guidance on next course of action. Promptly report violations or suspected violations through appropriate channels and Promptly complete COBC trainings and assessments, as well as attest to comply annually\"\n",
    "\n",
    "\n",
    "# Encode the sentences\n",
    "generated_embedding = model.encode(generated_answer, convert_to_tensor=True)\n",
    "retrieved_embedding = model.encode(retrieved_text, convert_to_tensor=True)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_similarity = util.pytorch_cos_sim(generated_embedding, retrieved_embedding)\n",
    "\n",
    "print(f\"Cosine Similarity: {cosine_similarity.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc8d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to input number of tokens generated from the answer above and split the answers based on sentence by sentence\n",
    "import re\n",
    "tokens=re.findall(r'\\w+', answer)\n",
    "num_tokens=len(tokens)\n",
    "\n",
    "print(f\"Number of tokens: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56035c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Split the answer into sentences\n",
    "sentences = nltk.sent_tokenize(answer)\n",
    "\n",
    "# List the sentences with an index\n",
    "for idx, sentence in enumerate(sentences, 1):\n",
    "    print(f\"{idx}. {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529717aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gtts import gTTS\n",
    "\n",
    "# Replace this with the path to your own folder\n",
    "output_dir = r\"C:\\Users\\imagi\\fastRAG\\audio\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Generate and save TTS for each sentence\n",
    "for idx, sentence in enumerate(sentences, 1):\n",
    "    tts = gTTS(text=sentence, lang='en')\n",
    "    audio_path = os.path.join(output_dir, f\"sentence_{idx}.mp3\")\n",
    "    tts.save(audio_path)\n",
    "    print(f\"Saved audio for sentence {idx} at {audio_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code here is to reduce the bluriness on the avatar (image)\n",
    "# import cv2\n",
    "# avatar_image = cv2.imread(r\"C:\\Users\\imagi\\Desktop\\videos(avatar)\\edited_idle_video-Scene-001-03.jpg\")\n",
    "# sharpen_filter = cv2.filter2D(avatar_image, -1, kernel=cv2.getGaussianKernel(5, -1))\n",
    "# cv2.imwrite(\"sharpened_avatar.jpg\", sharpen_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a4d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import threading\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "from queue import Queue\n",
    "from pydub import AudioSegment\n",
    "import simpleaudio as sa\n",
    "\n",
    "# Paths (adjust as needed)\n",
    "avatar_image_path = r\"C:\\Users\\imagi\\fastRAG\\sharpened_avatar.jpg\"\n",
    "wav2lip_repo_path = r\"C:\\Users\\imagi\\fastRAG\\Wav2Lip\"\n",
    "model_checkpoint_path = os.path.join(wav2lip_repo_path, \"checkpoints\", \"wav2lip.pth\")\n",
    "output_folder = r\"C:\\Users\\imagi\\fastRAG\\video_avatar\"\n",
    "audio_folder = r\"C:\\Users\\imagi\\fastRAG\\audio\"\n",
    "\n",
    "class VideoPlayer:\n",
    "    def __init__(self, idle_video):\n",
    "        self.queue = Queue()  # Queue to manage videos\n",
    "        self.idle_video = idle_video\n",
    "        self.playing = True  # Control playback\n",
    "        self.lock = threading.Lock()  # Lock to safely update the queue\n",
    "\n",
    "    def add_video(self, video_path, audio_path=None):\n",
    "        \"\"\"\n",
    "        Add a new video and its corresponding audio to the queue.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            self.queue.put((video_path, audio_path))\n",
    "            print(f\"Added video: {video_path} with audio: {audio_path}\")\n",
    "\n",
    "    def play_video(self, video_path, audio_path=None):\n",
    "        \"\"\"\n",
    "        Play a video file and optionally play its audio.\n",
    "        \"\"\"\n",
    "        print(f\"Playing video: {video_path}\")\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error opening video file: {video_path}\")\n",
    "            return\n",
    "\n",
    "        # Start audio playback if audio_path is provided\n",
    "        audio_thread = None\n",
    "        if audio_path:\n",
    "            audio_thread = threading.Thread(target=self.play_audio, args=(audio_path,))\n",
    "            audio_thread.start()\n",
    "\n",
    "        while cap.isOpened() and self.playing:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            cv2.imshow('Video Player', frame)\n",
    "            if cv2.waitKey(30) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "                self.playing = False\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        if audio_thread:\n",
    "            audio_thread.join()  # Wait for audio playback to finish\n",
    "\n",
    "    def play_videos(self):\n",
    "        \"\"\"\n",
    "        Continuously play videos, prioritizing queued videos over the idle video.\n",
    "        \"\"\"\n",
    "        while self.playing:\n",
    "            # Check the queue for videos\n",
    "            if not self.queue.empty():\n",
    "                video_path, audio_path = self.queue.get()\n",
    "                self.play_video(video_path, audio_path)\n",
    "            else:\n",
    "                # Play the idle video in a loop until a new video is added\n",
    "                self.play_video(self.idle_video)\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    @staticmethod\n",
    "    def play_audio(audio_path):\n",
    "        \"\"\"\n",
    "        Play an audio file.\n",
    "        \"\"\"\n",
    "        # Convert MP3 to WAV if necessary\n",
    "        if audio_path.endswith('.mp3'):\n",
    "            audio = AudioSegment.from_mp3(audio_path)\n",
    "            wav_path = audio_path.replace('.mp3', '.wav')\n",
    "            audio.export(wav_path, format=\"wav\")\n",
    "            audio_path = wav_path\n",
    "\n",
    "        # Play the WAV file\n",
    "        wave_obj = sa.WaveObject.from_wave_file(audio_path)\n",
    "        play_obj = wave_obj.play()\n",
    "        play_obj.wait_done()\n",
    "\n",
    "def process_lip_sync(idx, audio_path, player):\n",
    "    \"\"\"\n",
    "    Generate a lip-sync video for a given audio and add it to the player's queue.\n",
    "    \"\"\"\n",
    "    output_video_path = os.path.join(output_folder, f\"output_video_{idx}.mp4\")\n",
    "    output_combined_path = os.path.join(output_folder, f\"output_video_{idx}_combined.mp4\")\n",
    "\n",
    "\n",
    "    pads = [0, 10, 0, 0]\n",
    "    # Run Wav2Lip to generate the lip-sync video\n",
    "    command = [\n",
    "        'python', os.path.join(wav2lip_repo_path, 'inference.py'),\n",
    "        '--checkpoint_path', model_checkpoint_path,\n",
    "        '--face', avatar_image_path,\n",
    "        '--audio', audio_path,\n",
    "        '--outfile', output_video_path,\n",
    "        '--pads', *map(str, pads)\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "        print(f\"Lip-sync video generated for sentence {idx}!\")\n",
    "\n",
    "        # Combine the video and audio using ffmpeg\n",
    "        command_ffmpeg = [\n",
    "            'ffmpeg', '-i', output_video_path, '-i', audio_path,\n",
    "            '-c:v', 'libx264', '-c:a', 'aac', '-map', '0:v:0', '-map', '1:a:0', '-y', output_combined_path\n",
    "        ]\n",
    "        subprocess.run(command_ffmpeg, capture_output=True, text=True, check=True)\n",
    "        print(f\"Video and audio combined for sentence {idx}!\")\n",
    "\n",
    "        # Add the combined video to the player\n",
    "        player.add_video(output_combined_path, audio_path)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error generating video for sentence {idx}: {e}\")\n",
    "        print(\"STDOUT:\", e.stdout)\n",
    "        print(\"STDERR:\", e.stderr)\n",
    "\n",
    "# Initialize the VideoPlayer with the idle video\n",
    "idle_video_path = r\"C:\\Users\\imagi\\Desktop\\videos(avatar)\\edited_idle_video.mp4\"\n",
    "player = VideoPlayer(idle_video=idle_video_path)\n",
    "\n",
    "# Start the video player in a separate thread\n",
    "player_thread = threading.Thread(target=player.play_videos)\n",
    "player_thread.start()\n",
    "\n",
    "# Get all audio files in the audio folder\n",
    "audio_files = [f for f in os.listdir(audio_folder) if f.endswith('.mp3')]\n",
    "\n",
    "# Process each audio file in sequence\n",
    "for idx, audio_file in enumerate(audio_files, start=1):\n",
    "    audio_path = os.path.join(audio_folder, audio_file)\n",
    "    if os.path.exists(audio_path):\n",
    "        process_lip_sync(idx, audio_path, player)\n",
    "\n",
    "# Wait for the player thread to finish\n",
    "player_thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64068c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
